#spring.cloud.nacos.discovery.server-addr=localhost:8848
spring.application.name=zpain2
#spring.cloud.nacos.discovery.group=zpain
#spring.cloud.nacos.discovery.namespace=164265e8-9bd8-424d-a687-94cca4083a21
server.port=8091
#management.endpoint.health.show-details=always

mybatis-plus.mapper-locations=classpath*:/mapper/**/*.xml
mybatis-plus.configuration.map-underscore-to-camel-case=true
mybatis-plus.type-aliases-package=com.zpain.service.pojo
#mybatis-plus.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl

#sharding.jdbc.datasource.names=ds0,ds1
#sharding.jdbc.datasource.ds0.type=com.alibaba.druid.pool.DruidDataSource

spring.datasource.username=root
spring.datasource.password=root
spring.datasource.url=jdbc:mysql://localhost:3306/zpain_test?useSSL=false&useUnicode=true&characterEncoding=utf-8&serverTimezone=GMT%2B8
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver

spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
# 连接池的配置信息
# 初始化大小，最小，最大
spring.datasource.druid.initialSize=5
spring.datasource.druid.minIdle=5
spring.datasource.druid.maxActive=20
# 配置获取连接等待超时的时间
spring.datasource.druid.maxWait=60000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.druid.timeBetweenEvictionRunsMillis=60000
# 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.druid.minEvictableIdleTimeMillis=300000
spring.datasource.druid.validationQuery=SELECT 1 FROM DUAL
spring.datasource.druid.testWhileIdle=true
spring.datasource.druid.testOnBorrow=false
spring.datasource.druid.testOnReturn=false
# 打开PSCache，并且指定每个连接上PSCache的大小
spring.datasource.druid.poolPreparedStatements=true
spring.datasource.druid.maxPoolPreparedStatementPerConnectionSize=20
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙 stat:监控统计 log4j:日志 wall:防御sql注入
spring.datasource.druid.filters=stat,wall
#是否启用StatViewServlet默认值true
spring.datasource.druid.stat-view-servlet.enabled= true
#访问路径为/druid时，跳转到StatViewServlet
spring.datasource.druid.stat-view-servlet.url-pattern=/druid/*
# 是否能够重置数据
spring.datasource.druid.stat-view-servlet.reset-enable=false
# 需要账号密码才能访问控制台，默认为root
spring.datasource.druid.stat-view-servlet.login-username=druid
spring.datasource.druid.stat-view-servlet.login-password=druid

spring.redis.host=localhost
spring.redis.database=0
spring.redis.port=6379
mybatis-plus.configuration.log-impl=org.apache.ibatis.logging.stdout.StdOutImpl

#### xxl-job admin address list, such as "http://address" or "http://address01,http://address02"
#xxl.job.admin.addresses=http://127.0.0.1:8080/xxl-job-admin
#
#### xxl-job, access token
#xxl.job.accessToken=zpain123
#
#### xxl-job executor appname
#xxl.job.executor.appname=demo
#### xxl-job executor registry-address: default use address to registry , otherwise use ip:port if address is null
#xxl.job.executor.address=
#### xxl-job executor server-info
#xxl.job.executor.ip=
#xxl.job.executor.port=0
#### xxl-job executor log-path
#xxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler
#### xxl-job executor log-retention-days
#xxl.job.executor.logretentiondays=30

## Akka port, default is 27777
#powerjob.worker.akka-port=27777
## Application name, used for grouping applications. Recommend to set the same value as project name.
#powerjob.worker.app-name=powerjob-agent-demo
## Address of PowerJob-server node(s). Ip:port or domain. Multiple addresses should be separated with comma.
#powerjob.worker.server-address=127.0.0.1:7700,127.0.0.1:7701
## Store strategy of H2 database. disk or memory. Default value is disk.
#powerjob.worker.store-strategy=disk
## Max length of result. Results that are longer than the value will be truncated.
#powerjob.worker.max-result-length=4096
## Max length of appended workflow context . Appended workflow context value that is longer than the value will be ignore.
#powerjob.worker.max-appended-wf-context-length=4096

spring.cache.type=redis